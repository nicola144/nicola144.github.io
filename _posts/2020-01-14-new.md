# Improved Auxiliary Particle Filters

In this post, my aim is to introduce a recent technique called IAPF (Improved Auxiliary Particle Filter). 
The ideal target reader has familiarity with Bayesian inference and basics of particle filters. However, the latter is much more optional, and if you are familiar with Bayesian inference in a "batch" setting (where data is processed all at once), you should be able to follow. If you are not, I will write a blogpost on Bayesian inference that assumes no prior background except basic rules of probability.

1. [Preliminaries](#introduction)
2. [Particle Filters](#paragraph1)

## Preliminaries on sequential Bayesian inference 

In Bayesian inference we want to update our beliefs on the state of some random variables, which could represent parameters of a parametric statistical model or represent some unobserved data generating process. Focussing on the "updating" perspective, the step to using Bayesian methods to represent dynamical systems is quite natural. The field of statistical signal processing has been using the rule of probabilities to model object tracking, navigation and even.. spread of infectious diseases. 
The probabilistic evolution of a dynamical system is often called a *state space model*. This is just an abstraction of how we think the state of the system evolves over time. Imagine we are tracking a robot's position (x,y coordinates) and bearing: these constitute a 3 element vector. At some specific timestep, we can have a belief, i.e. a probability distribution that represents how likely we think the robot is currently assuming a certain bearing etc. If we start with a prior, and define some likelihood function/ sampling process that we believe generates what we observe, we can update our belief over the system's state with the rules of probabilty.
Let the (uknown) state of the system at time $t$ be the vector valued random variable $\mathbf{s}_{t}$.  
We observe this state through a (noisy) measurement $\mathbf{v}_{y}$ (where 'v' stands for 'visible). 
Now we have to start making more assumptions. What does our belief on $\mathbf{s}_{t}$ depend on ? 
Suprisingly to me, it turns out for **a lot** of applications it just needs to depend on the state at the previous timestep. 
In other words, we can say that $\mathbf{s}_{t}$ is sampled from some density $f$ conditional on $\mathbf{s}_{t-1}$:
$$
\mathbf{s}_{t} \sim f(\mathbf{s} \mid \mathbf{s}_{t-1})
$$

<p align="center"><img src="https://rawgit.com/nicola144/nicola144/master/svgs/0b5b7ecf3db49eb116afd50259b14b79.svg?invert_in_darkmode" align=middle width=270.0678486pt height=41.09589pt/></p>
